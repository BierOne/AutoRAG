{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded YAML Data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'vectordb': [{'name': 'chroma_mpnet',\n",
       "   'db_type': 'chroma',\n",
       "   'client_type': 'persistent',\n",
       "   'collection_name': 'huggingface_all_mpnet_base_v2',\n",
       "   'embedding_model': 'huggingface_all_mpnet_base_v2',\n",
       "   'path': '/home/lyb/RAG/experiments/chroma_mpnet'}],\n",
       " 'node_lines': [{'node_line_name': 'retrieve_node_line',\n",
       "   'nodes': [{'node_type': 'retrieval',\n",
       "     'strategy': {'metrics': ['retrieval_f1',\n",
       "       'retrieval_recall',\n",
       "       'retrieval_precision']},\n",
       "     'top_k': 3,\n",
       "     'modules': [{'module_type': 'bm25'},\n",
       "      {'module_type': 'vectordb', 'vectordb': 'chroma_mpnet'},\n",
       "      {'module_type': 'hybrid_rrf',\n",
       "       'target_modules': \"('bm25', 'vectordb')\",\n",
       "       'rrf_k': [3, 5, 10]},\n",
       "      {'module_type': 'hybrid_cc',\n",
       "       'target_modules': \"('bm25', 'vectordb')\",\n",
       "       'weights': '(0.5, 0.5)'}]}]},\n",
       "  {'node_line_name': 'post_retrieve_node_line',\n",
       "   'nodes': [{'node_type': 'prompt_maker',\n",
       "     'strategy': {'metrics': ['meteor', 'rouge', 'bert_score']},\n",
       "     'modules': [{'module_type': 'fstring',\n",
       "       'prompt': 'Read the passages and answer the given question. \\n Question: {query} \\n Passage: {retrieved_contents} \\n Answer : '}]},\n",
       "    {'node_type': 'generator',\n",
       "     'strategy': {'metrics': ['meteor', 'rouge', 'bert_score']},\n",
       "     'modules': [{'module_type': 'llama_index_llm',\n",
       "       'llm': 'ollama',\n",
       "       'model': 'llama3',\n",
       "       'temperature': 0.5,\n",
       "       'batch': 1}]}]}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"ollama_config.yaml\", \"r\") as file:\n",
    "    data = yaml.safe_load(file)\n",
    "\n",
    "print(\"Loaded YAML Data:\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_modules = [{'module_type': 'HybridCC',\n",
    "                            'target_module_params': [{'top_k': 3, 'vectordb': 'chroma_mpnet'}, {'top_k': 3}],\n",
    "                            'target_modules': ['VectorDB', 'BM25'],\n",
    "                            'weights': [0.3, 0.7]},\n",
    "                {'module_type': 'hybrid_cc',\n",
    "                    'target_modules': \"('bm25', 'vectordb')\",\n",
    "                    'target_module_params': [{'top_k': 3}, {'top_k': 3, 'vectordb': 'chroma_mpnet'}],\n",
    "                    'weights': ['(0.5, 0.5)']},\n",
    "                {'module_type': 'hybrid_cc',\n",
    "                    'target_modules': \"('bm25', 'vectordb')\",\n",
    "                    'target_module_params': [{'top_k': 3}, {'top_k': 3, 'vectordb': 'chroma_mpnet'}],\n",
    "                    'weights': ['(0.7, 0.3)']},\n",
    "                {'module_type': 'bm25'},\n",
    "                {'module_type': 'vectordb', 'vectordb': 'chroma_mpnet'},\n",
    "                {'module_type': 'hybrid_rrf',\n",
    "                    'target_modules': \"('bm25', 'vectordb')\",\n",
    "                    'target_module_params': [{'top_k': 3}, {'top_k': 3, 'vectordb': 'chroma_mpnet'}],\n",
    "                    'rrf_k': [5]},\n",
    "                {'module_type': 'hybrid_rrf',\n",
    "                    'target_modules': \"('bm25', 'vectordb')\",\n",
    "                    'target_module_params': [{'top_k': 3}, {'top_k': 3, 'vectordb': 'chroma_mpnet'}],\n",
    "                    'rrf_k': [3]},\n",
    "                {'module_type': 'hybrid_rrf',\n",
    "                    'target_modules': \"('bm25', 'vectordb')\",\n",
    "                    'target_module_params': [{'top_k': 3}, {'top_k': 3, 'vectordb': 'chroma_mpnet'}],\n",
    "                    'rrf_k': [10]},]\n",
    "\n",
    "for i, module in enumerate(test_modules):\n",
    "    for node in data['node_lines']:\n",
    "        if node['node_line_name'] == 'retrieve_node_line':\n",
    "            for node_line in node['nodes']:\n",
    "                node_line['modules'] = [module]\n",
    "\n",
    "            # Save the modified data back to a YAML file\n",
    "            with open(f\"./candidate_config/ollama_config_{i}.yaml\", \"w\") as file:\n",
    "                yaml.safe_dump(data, file, default_flow_style=False, sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node_lines': [{'node_line_name': 'retrieve_node_line',\n",
       "   'nodes': [{'modules': [{'module_type': 'HybridCC',\n",
       "       'target_module_params': [{'top_k': 3, 'vectordb': 'chroma_mpnet'},\n",
       "        {'top_k': 3}],\n",
       "       'target_modules': ['VectorDB', 'BM25'],\n",
       "       'top_k': 3,\n",
       "       'weight': 0.0,\n",
       "       'weights': [0.3, 0.7]}],\n",
       "     'node_type': 'retrieval',\n",
       "     'strategy': {'metrics': ['retrieval_f1',\n",
       "       'retrieval_recall',\n",
       "       'retrieval_precision']}}]},\n",
       "  {'node_line_name': 'post_retrieve_node_line',\n",
       "   'nodes': [{'modules': [{'module_type': 'Fstring',\n",
       "       'prompt': 'Read the passages and answer the given question. \\n Question: {query} \\n Passage: {retrieved_contents} \\n Answer : '}],\n",
       "     'node_type': 'prompt_maker',\n",
       "     'strategy': {'metrics': ['meteor', 'rouge', 'bert_score']}},\n",
       "    {'modules': [{'batch': 1,\n",
       "       'llm': 'ollama',\n",
       "       'model': 'llama3',\n",
       "       'module_type': 'LlamaIndexLLM',\n",
       "       'temperature': 0.5}],\n",
       "     'node_type': 'generator',\n",
       "     'strategy': {'metrics': ['meteor', 'rouge', 'bert_score']}}]}],\n",
       " 'vectordb': [{'client_type': 'persistent',\n",
       "   'collection_name': 'huggingface_all_mpnet_base_v2',\n",
       "   'db_type': 'chroma',\n",
       "   'embedding_model': 'huggingface_all_mpnet_base_v2',\n",
       "   'name': 'chroma_mpnet',\n",
       "   'path': '/home/lyb/RAG/experiments/chroma_mpnet'}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"eli5/0/best.yaml\", \"r\") as file:\n",
    "    tmp = yaml.safe_load(file)\n",
    "\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autorag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
