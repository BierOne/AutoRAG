{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "main_dir = Path(\"/home/lyb\")\n",
    "data_dir = main_dir / \"RAG/data/eli5_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_eli5_dataset(save_path):\n",
    "    # set file path\n",
    "    file_path = \"MarkrAI/eli5_sample_autorag\"\n",
    "\n",
    "    # load dataset\n",
    "    corpus_dataset = load_dataset(file_path, \"corpus\")['train'].to_pandas()\n",
    "    qa_train_dataset = load_dataset(file_path, \"qa\")['train'].to_pandas()\n",
    "    qa_test_dataset = load_dataset(file_path, \"qa\")['test'].to_pandas()\n",
    "\n",
    "    # save data\n",
    "    if os.path.exists(os.path.join(save_path, \"corpus.parquet\")) is True:\n",
    "        raise ValueError(\"corpus.parquet already exists\")\n",
    "    if os.path.exists(os.path.join(save_path, \"qa.parquet\")) is True:\n",
    "        raise ValueError(\"qa.parquet already exists\")\n",
    "    corpus_dataset.to_parquet(os.path.join(save_path, \"corpus.parquet\"))\n",
    "    qa_train_dataset.to_parquet(os.path.join(save_path, \"qa_train.parquet\"))\n",
    "    qa_test_dataset.to_parquet(os.path.join(save_path, \"qa_test.parquet\"))\n",
    "\n",
    "\n",
    "load_eli5_dataset(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/20/24 06:10:17] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>__init__.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span><span style=\"font-weight: bold\">]</span> &gt;&gt; You are using API version of AutoRAG.To use local <a href=\"file:///home/lyb/RAG/AutoRAG/autorag/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lyb/RAG/AutoRAG/autorag/__init__.py#100\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">100</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         version, run pip install <span style=\"color: #008000; text-decoration-color: #008000\">'AutoRAG[gpu]'</span>                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/20/24 06:10:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0m__init__.py:\u001b[1;36m100\u001b[0m\u001b[1m]\u001b[0m >> You are using API version of AutoRAG.To use local \u001b]8;id=567134;file:///home/lyb/RAG/AutoRAG/autorag/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=746580;file:///home/lyb/RAG/AutoRAG/autorag/__init__.py#100\u001b\\\u001b[2m100\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         version, run pip install \u001b[32m'AutoRAG\u001b[0m\u001b[32m[\u001b[0m\u001b[32mgpu\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>__init__.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span><span style=\"font-weight: bold\">]</span> &gt;&gt; You are using API version of AutoRAG.To use local <a href=\"file:///home/lyb/RAG/AutoRAG/autorag/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lyb/RAG/AutoRAG/autorag/__init__.py#128\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         version, run pip install <span style=\"color: #008000; text-decoration-color: #008000\">'AutoRAG[gpu]'</span>                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0m__init__.py:\u001b[1;36m128\u001b[0m\u001b[1m]\u001b[0m >> You are using API version of AutoRAG.To use local \u001b]8;id=406636;file:///home/lyb/RAG/AutoRAG/autorag/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=402932;file:///home/lyb/RAG/AutoRAG/autorag/__init__.py#128\u001b\\\u001b[2m128\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         version, run pip install \u001b[32m'AutoRAG\u001b[0m\u001b[32m[\u001b[0m\u001b[32mgpu\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "qa_df = pd.read_parquet(data_dir / 'qa_train.parquet')\n",
    "sample_qa_df = qa_df.sample(20, random_state=42) # In this sample code, we will only optimize pipeline with 20 samples just for testing.\n",
    "sample_qa_df.reset_index(drop=True, inplace=True)\n",
    "sample_qa_df.to_parquet(data_dir / 'qa_sample.parquet')\n",
    "\n",
    "from itertools import chain\n",
    "from autorag.utils.util import to_list\n",
    "# We drop unused corpus dataframe for faster inference.\n",
    "corpus_df = pd.read_parquet(data_dir / 'corpus.parquet')\n",
    "target_retrieval_gts = list(chain.from_iterable(to_list(sample_qa_df[\"retrieval_gt\"].tolist())))\n",
    "target_retrieval_gts = list(chain.from_iterable(target_retrieval_gts))\n",
    "sample_corpus_df = corpus_df[corpus_df[\"doc_id\"].isin(target_retrieval_gts)]\n",
    "sample_corpus_df.reset_index(drop=True, inplace=True)\n",
    "sample_corpus_df.to_parquet(data_dir / 'corpus_sample.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from autorag.schema.metricinput import MetricInput\n",
    "from autorag.evaluation import evaluate_generation\n",
    "\n",
    "# Load QA dataset\n",
    "qa_df = pd.read_parquet(\"qa.parquet\", engine=\"pyarrow\")\n",
    "\n",
    "# Prepare MetricInput list\n",
    "metric_inputs = [\n",
    "    MetricInput(query=row[\"query\"], generation_gt=row[\"generation_gt\"])\n",
    "    for _, row in qa_df.iterrows()\n",
    "]\n",
    "\n",
    "# Define custom generation function with decorator\n",
    "@evaluate_generation(\n",
    "    metric_inputs=metric_inputs,\n",
    "    metrics=[\"bleu\", \"meteor\", \"rouge\"]\n",
    ")\n",
    "def custom_generation(queries):\n",
    "    # Implement your generation logic\n",
    "    return generated_texts, [[1, 30]] * len(generated_texts), [[-1, -1.3]] * len(generated_texts)\n",
    "\n",
    "# Evaluate generation performance\n",
    "generation_result_df = custom_generation(qa_df[\"query\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_id\" in DeployedModel has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceLLM has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_kwargs\" in HuggingFaceLLM has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceInferenceAPI has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in TextGenerationInference has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from autorag.evaluator import Evaluator\n",
    "evaluator = Evaluator(qa_data_path=(data_dir/'qa_sample.parquet').as_posix(), corpus_data_path=(data_dir/'corpus.parquet').as_posix(),\n",
    "                      project_dir='./eli5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/22/24 03:13:52] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>evaluator.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">228</span><span style=\"font-weight: bold\">]</span> &gt;&gt; Embedding BM25 corpus<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                        <a href=\"file:///home/lyb/RAG/AutoRAG/autorag/evaluator.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">evaluator.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lyb/RAG/AutoRAG/autorag/evaluator.py#228\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">228</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/22/24 03:13:52]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mevaluator.py:\u001b[1;36m228\u001b[0m\u001b[1m]\u001b[0m >> Embedding BM25 corpus\u001b[33m...\u001b[0m                        \u001b]8;id=200867;file:///home/lyb/RAG/AutoRAG/autorag/evaluator.py\u001b\\\u001b[2mevaluator.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=58112;file:///home/lyb/RAG/AutoRAG/autorag/evaluator.py#228\u001b\\\u001b[2m228\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/22/24 03:13:53] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>evaluator.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">248</span><span style=\"font-weight: bold\">]</span> &gt;&gt; BM25 corpus embedding complete.                 <a href=\"file:///home/lyb/RAG/AutoRAG/autorag/evaluator.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">evaluator.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lyb/RAG/AutoRAG/autorag/evaluator.py#248\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">248</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/22/24 03:13:53]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mevaluator.py:\u001b[1;36m248\u001b[0m\u001b[1m]\u001b[0m >> BM25 corpus embedding complete.                 \u001b]8;id=959067;file:///home/lyb/RAG/AutoRAG/autorag/evaluator.py\u001b\\\u001b[2mevaluator.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=461185;file:///home/lyb/RAG/AutoRAG/autorag/evaluator.py#248\u001b\\\u001b[2m248\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4dd690978104f60b64ffddaf556ca8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>SentenceTransformer.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">218</span><span style=\"font-weight: bold\">]</span> &gt;&gt; Load pretrained             <a href=\"file:///home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">SentenceTransformer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py#218\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">218</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         SentenceTransformer:                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                          </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         sentence-transformers/all-mpnet-base-v2                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                          </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mSentenceTransformer.py:\u001b[1;36m218\u001b[0m\u001b[1m]\u001b[0m >> Load pretrained             \u001b]8;id=287052;file:///home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py\u001b\\\u001b[2mSentenceTransformer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=602151;file:///home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py#218\u001b\\\u001b[2m218\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         SentenceTransformer:                                        \u001b[2m                          \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         sentence-transformers/all-mpnet-base-v2                     \u001b[2m                          \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: \n",
       "FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will \n",
       "be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: \n",
       "https://github.com/huggingface/transformers/issues/31884\n",
       "  warnings.warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: \n",
       "FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will \n",
       "be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: \n",
       "https://github.com/huggingface/transformers/issues/31884\n",
       "  warnings.warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/22/24 03:13:57] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>SentenceTransformer.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">357</span><span style=\"font-weight: bold\">]</span> &gt;&gt; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> prompts are loaded, with  <a href=\"file:///home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">SentenceTransformer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py#357\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">357</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         the keys: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'query'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'text'</span><span style=\"font-weight: bold\">]</span>                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                          </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/22/24 03:13:57]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mSentenceTransformer.py:\u001b[1;36m357\u001b[0m\u001b[1m]\u001b[0m >> \u001b[1;36m2\u001b[0m prompts are loaded, with  \u001b]8;id=517001;file:///home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py\u001b\\\u001b[2mSentenceTransformer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=387527;file:///home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py#357\u001b\\\u001b[2m357\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         the keys: \u001b[1m[\u001b[0m\u001b[32m'query'\u001b[0m, \u001b[32m'text'\u001b[0m\u001b[1m]\u001b[0m                                 \u001b[2m                          \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>posthog.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span><span style=\"font-weight: bold\">]</span> &gt;&gt; Anonymized telemetry enabled. See                     <a href=\"file:///home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/chromadb/telemetry/product/posthog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">posthog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/chromadb/telemetry/product/posthog.py#22\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">22</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://docs.trychroma.com/telemetry</span> for more information.               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mposthog.py:\u001b[1;36m22\u001b[0m\u001b[1m]\u001b[0m >> Anonymized telemetry enabled. See                     \u001b]8;id=467190;file:///home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/chromadb/telemetry/product/posthog.py\u001b\\\u001b[2mposthog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=836752;file:///home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/chromadb/telemetry/product/posthog.py#22\u001b\\\u001b[2m22\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;94mhttps://docs.trychroma.com/telemetry\u001b[0m for more information.               \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/22/24 03:14:07] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>evaluator.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">205</span><span style=\"font-weight: bold\">]</span> &gt;&gt; Running node line retrieve_node_line<span style=\"color: #808000; text-decoration-color: #808000\">...</span>         <a href=\"file:///home/lyb/RAG/AutoRAG/autorag/evaluator.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">evaluator.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lyb/RAG/AutoRAG/autorag/evaluator.py#205\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">205</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/22/24 03:14:07]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mevaluator.py:\u001b[1;36m205\u001b[0m\u001b[1m]\u001b[0m >> Running node line retrieve_node_line\u001b[33m...\u001b[0m         \u001b]8;id=65749;file:///home/lyb/RAG/AutoRAG/autorag/evaluator.py\u001b\\\u001b[2mevaluator.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=649551;file:///home/lyb/RAG/AutoRAG/autorag/evaluator.py#205\u001b\\\u001b[2m205\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>node.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">55</span><span style=\"font-weight: bold\">]</span> &gt;&gt; Running node retrieval<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                   <a href=\"file:///home/lyb/RAG/AutoRAG/autorag/schema/node.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">node.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lyb/RAG/AutoRAG/autorag/schema/node.py#55\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">55</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mnode.py:\u001b[1;36m55\u001b[0m\u001b[1m]\u001b[0m >> Running node retrieval\u001b[33m...\u001b[0m                                   \u001b]8;id=745901;file:///home/lyb/RAG/AutoRAG/autorag/schema/node.py\u001b\\\u001b[2mnode.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=426083;file:///home/lyb/RAG/AutoRAG/autorag/schema/node.py#55\u001b\\\u001b[2m55\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>run.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">165</span><span style=\"font-weight: bold\">]</span> &gt;&gt; Running retrieval node - semantic retrieval module<span style=\"color: #808000; text-decoration-color: #808000\">...</span>       <a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/run.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">run.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/run.py#165\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">165</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mrun.py:\u001b[1;36m165\u001b[0m\u001b[1m]\u001b[0m >> Running retrieval node - semantic retrieval module\u001b[33m...\u001b[0m       \u001b]8;id=155285;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/run.py\u001b\\\u001b[2mrun.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=947220;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/run.py#165\u001b\\\u001b[2m165\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>base.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span><span style=\"font-weight: bold\">]</span> &gt;&gt; Initialize retrieval node - VectorDB                        <a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py#18\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mbase.py:\u001b[1;36m18\u001b[0m\u001b[1m]\u001b[0m >> Initialize retrieval node - VectorDB                        \u001b]8;id=412549;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=723208;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py#18\u001b\\\u001b[2m18\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>base.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span><span style=\"font-weight: bold\">]</span> &gt;&gt; Running retrieval node - VectorDB module<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                 <a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mbase.py:\u001b[1;36m31\u001b[0m\u001b[1m]\u001b[0m >> Running retrieval node - VectorDB module\u001b[33m...\u001b[0m                 \u001b]8;id=122027;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=301669;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "360d0eea4b614c578f9a008d1332945c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ab339255b024989b9c86010b78b9ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "868cae67364743e2bcb034955af8aa01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ddd091af63d4aa8999de144d98afdc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6952692a67354d56b23e68d1bab66b2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a38a687f9954112bf3711771afd079d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "868801964dbd4e8a9f8f5c85016c559a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f150b901dc24f45972cf6e8977a515a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b16a7fbb5c471b8c702a25f6e6550e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f78190890fc24396acdf558a18996f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0701e35c4cf04f4ebb83616043f7c24a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50f9ff3ace814b0381d3b2b1c773ee97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6843fa7c15b7408d8df93139fd853bf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5b3f5e348a743f3bc44229003b92b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0697b04200704908a2a52ccc5a214add",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89e5872c13524dcc9460ee2f18d47dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d64d8e1bd8a45dc82caab6163259a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a91a818e3de04f23b5288926b0e2273b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba2bbd6183546acb49f2f34c4b075ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77291c97bb184148a05d1b631a3a4e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/22/24 03:14:09] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>base.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span><span style=\"font-weight: bold\">]</span> &gt;&gt; Deleting retrieval node - VectorDB module<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                <a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py#28\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">28</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/22/24 03:14:09]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mbase.py:\u001b[1;36m28\u001b[0m\u001b[1m]\u001b[0m >> Deleting retrieval node - VectorDB module\u001b[33m...\u001b[0m                \u001b]8;id=907508;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=660626;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py#28\u001b\\\u001b[2m28\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>run.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">196</span><span style=\"font-weight: bold\">]</span> &gt;&gt; Running retrieval node - lexical retrieval module<span style=\"color: #808000; text-decoration-color: #808000\">...</span>        <a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/run.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">run.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/run.py#196\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">196</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mrun.py:\u001b[1;36m196\u001b[0m\u001b[1m]\u001b[0m >> Running retrieval node - lexical retrieval module\u001b[33m...\u001b[0m        \u001b]8;id=534194;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/run.py\u001b\\\u001b[2mrun.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=62491;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/run.py#196\u001b\\\u001b[2m196\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>base.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span><span style=\"font-weight: bold\">]</span> &gt;&gt; Initialize retrieval node - BM25                            <a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py#18\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mbase.py:\u001b[1;36m18\u001b[0m\u001b[1m]\u001b[0m >> Initialize retrieval node - BM25                            \u001b]8;id=600790;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=434365;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py#18\u001b\\\u001b[2m18\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>base.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span><span style=\"font-weight: bold\">]</span> &gt;&gt; Running retrieval node - BM25 module<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                     <a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mbase.py:\u001b[1;36m31\u001b[0m\u001b[1m]\u001b[0m >> Running retrieval node - BM25 module\u001b[33m...\u001b[0m                     \u001b]8;id=119526;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=873914;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>run.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">227</span><span style=\"font-weight: bold\">]</span> &gt;&gt; Running retrieval node - hybrid retrieval module<span style=\"color: #808000; text-decoration-color: #808000\">...</span>         <a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/run.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">run.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/run.py#227\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">227</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mrun.py:\u001b[1;36m227\u001b[0m\u001b[1m]\u001b[0m >> Running retrieval node - hybrid retrieval module\u001b[33m...\u001b[0m         \u001b]8;id=754532;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/run.py\u001b\\\u001b[2mrun.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=599661;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/run.py#227\u001b\\\u001b[2m227\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>base.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span><span style=\"font-weight: bold\">]</span> &gt;&gt; Initialize retrieval node - VectorDB                        <a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py#18\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mbase.py:\u001b[1;36m18\u001b[0m\u001b[1m]\u001b[0m >> Initialize retrieval node - VectorDB                        \u001b]8;id=277747;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=871036;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py#18\u001b\\\u001b[2m18\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/22/24 03:14:10] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>base.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span><span style=\"font-weight: bold\">]</span> &gt;&gt; Running retrieval node - VectorDB module<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                 <a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/22/24 03:14:10]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mbase.py:\u001b[1;36m31\u001b[0m\u001b[1m]\u001b[0m >> Running retrieval node - VectorDB module\u001b[33m...\u001b[0m                 \u001b]8;id=161548;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=156477;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e99c2913d1f54133bf5f4d685a3e5710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>base.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span><span style=\"font-weight: bold\">]</span> &gt;&gt; Deleting retrieval node - VectorDB module<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                <a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py#28\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">28</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mbase.py:\u001b[1;36m28\u001b[0m\u001b[1m]\u001b[0m >> Deleting retrieval node - VectorDB module\u001b[33m...\u001b[0m                \u001b]8;id=801493;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=748636;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py#28\u001b\\\u001b[2m28\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>base.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span><span style=\"font-weight: bold\">]</span> &gt;&gt; Initialize retrieval node - BM25                            <a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py#18\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mbase.py:\u001b[1;36m18\u001b[0m\u001b[1m]\u001b[0m >> Initialize retrieval node - BM25                            \u001b]8;id=877577;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=202447;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py#18\u001b\\\u001b[2m18\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/22/24 03:14:11] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>base.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span><span style=\"font-weight: bold\">]</span> &gt;&gt; Running retrieval node - BM25 module<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                     <a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/22/24 03:14:11]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mbase.py:\u001b[1;36m31\u001b[0m\u001b[1m]\u001b[0m >> Running retrieval node - BM25 module\u001b[33m...\u001b[0m                     \u001b]8;id=295048;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=431566;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>base.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span><span style=\"font-weight: bold\">]</span> &gt;&gt; Deleting retrieval node - BM25 module<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                    <a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py#28\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">28</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mbase.py:\u001b[1;36m28\u001b[0m\u001b[1m]\u001b[0m >> Deleting retrieval node - BM25 module\u001b[33m...\u001b[0m                    \u001b]8;id=706177;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=287295;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py#28\u001b\\\u001b[2m28\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluator.start_trial('./ollama_config.yaml', skip_validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node_lines': [{'node_line_name': 'retrieve_node_line',\n",
       "   'nodes': [{'node_type': 'retrieval',\n",
       "     'strategy': {'metrics': ['retrieval_f1',\n",
       "       'retrieval_recall',\n",
       "       'retrieval_precision']},\n",
       "     'modules': [{'module_type': 'HybridCC',\n",
       "       'top_k': 3,\n",
       "       'target_modules': ('VectorDB', 'BM25'),\n",
       "       'weights': (0.3, 0.7),\n",
       "       'weight': 0.0,\n",
       "       'target_module_params': ({'top_k': 3, 'vectordb': 'chroma_mpnet'},\n",
       "        {'top_k': 3})}]}]},\n",
       "  {'node_line_name': 'post_retrieve_node_line',\n",
       "   'nodes': [{'node_type': 'prompt_maker',\n",
       "     'strategy': {'metrics': ['meteor', 'rouge', 'bert_score']},\n",
       "     'modules': [{'module_type': 'Fstring',\n",
       "       'prompt': 'Read the passages and answer the given question. \\n Question: {query} \\n Passage: {retrieved_contents} \\n Answer : '}]},\n",
       "    {'node_type': 'generator',\n",
       "     'strategy': {'metrics': ['meteor', 'rouge', 'bert_score']},\n",
       "     'modules': [{'module_type': 'LlamaIndexLLM',\n",
       "       'llm': 'ollama',\n",
       "       'model': 'llama3',\n",
       "       'temperature': 0.5,\n",
       "       'batch': 1}]}]}],\n",
       " 'vectordb': [{'client_type': 'persistent',\n",
       "   'collection_name': 'huggingface_all_mpnet_base_v2',\n",
       "   'db_type': 'chroma',\n",
       "   'embedding_model': 'huggingface_all_mpnet_base_v2',\n",
       "   'name': 'chroma_mpnet',\n",
       "   'path': '/home/lyb/RAG/experiments/chroma_mpnet'}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autorag.deploy import extract_best_config\n",
    "extract_best_config(trial_path='./eli5/0', output_path='./eli5/0/best.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/22/24 03:39:31] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>base.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span><span style=\"font-weight: bold\">]</span> &gt;&gt; Initialize retrieval node - HybridCC                        <a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py#18\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/22/24 03:39:31]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mbase.py:\u001b[1;36m18\u001b[0m\u001b[1m]\u001b[0m >> Initialize retrieval node - HybridCC                        \u001b]8;id=808566;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=605026;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py#18\u001b\\\u001b[2m18\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>base.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span><span style=\"font-weight: bold\">]</span> &gt;&gt; Initialize retrieval node - VectorDB                        <a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py#18\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mbase.py:\u001b[1;36m18\u001b[0m\u001b[1m]\u001b[0m >> Initialize retrieval node - VectorDB                        \u001b]8;id=159339;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=567816;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py#18\u001b\\\u001b[2m18\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/22/24 03:39:32] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>SentenceTransformer.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">218</span><span style=\"font-weight: bold\">]</span> &gt;&gt; Load pretrained             <a href=\"file:///home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">SentenceTransformer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py#218\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">218</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         SentenceTransformer:                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                          </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         sentence-transformers/all-mpnet-base-v2                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                          </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/22/24 03:39:32]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mSentenceTransformer.py:\u001b[1;36m218\u001b[0m\u001b[1m]\u001b[0m >> Load pretrained             \u001b]8;id=301388;file:///home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py\u001b\\\u001b[2mSentenceTransformer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=192735;file:///home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py#218\u001b\\\u001b[2m218\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         SentenceTransformer:                                        \u001b[2m                          \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         sentence-transformers/all-mpnet-base-v2                     \u001b[2m                          \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/22/24 03:39:35] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>SentenceTransformer.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">357</span><span style=\"font-weight: bold\">]</span> &gt;&gt; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> prompts are loaded, with  <a href=\"file:///home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">SentenceTransformer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py#357\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">357</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         the keys: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'query'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'text'</span><span style=\"font-weight: bold\">]</span>                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                          </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/22/24 03:39:35]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mSentenceTransformer.py:\u001b[1;36m357\u001b[0m\u001b[1m]\u001b[0m >> \u001b[1;36m2\u001b[0m prompts are loaded, with  \u001b]8;id=751678;file:///home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py\u001b\\\u001b[2mSentenceTransformer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=263505;file:///home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py#357\u001b\\\u001b[2m357\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         the keys: \u001b[1m[\u001b[0m\u001b[32m'query'\u001b[0m, \u001b[32m'text'\u001b[0m\u001b[1m]\u001b[0m                                 \u001b[2m                          \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>posthog.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span><span style=\"font-weight: bold\">]</span> &gt;&gt; Anonymized telemetry enabled. See                     <a href=\"file:///home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/chromadb/telemetry/product/posthog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">posthog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/chromadb/telemetry/product/posthog.py#22\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">22</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://docs.trychroma.com/telemetry</span> for more information.               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mposthog.py:\u001b[1;36m22\u001b[0m\u001b[1m]\u001b[0m >> Anonymized telemetry enabled. See                     \u001b]8;id=263704;file:///home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/chromadb/telemetry/product/posthog.py\u001b\\\u001b[2mposthog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=959736;file:///home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/chromadb/telemetry/product/posthog.py#22\u001b\\\u001b[2m22\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;94mhttps://docs.trychroma.com/telemetry\u001b[0m for more information.               \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/22/24 03:39:36] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>base.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span><span style=\"font-weight: bold\">]</span> &gt;&gt; Initialize retrieval node - BM25                            <a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py#18\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/22/24 03:39:36]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mbase.py:\u001b[1;36m18\u001b[0m\u001b[1m]\u001b[0m >> Initialize retrieval node - BM25                            \u001b]8;id=734461;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=164409;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py#18\u001b\\\u001b[2m18\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>base.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span><span style=\"font-weight: bold\">]</span> &gt;&gt; Initialize prompt maker node - Fstring module<span style=\"color: #808000; text-decoration-color: #808000\">...</span>            <a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/promptmaker/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/promptmaker/base.py#15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mbase.py:\u001b[1;36m15\u001b[0m\u001b[1m]\u001b[0m >> Initialize prompt maker node - Fstring module\u001b[33m...\u001b[0m            \u001b]8;id=625735;file:///home/lyb/RAG/AutoRAG/autorag/nodes/promptmaker/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=484713;file:///home/lyb/RAG/AutoRAG/autorag/nodes/promptmaker/base.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>base.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span><span style=\"font-weight: bold\">]</span> &gt;&gt; Initialize generator node - LlamaIndexLLM                   <a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/generator/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/generator/base.py#19\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">19</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mbase.py:\u001b[1;36m19\u001b[0m\u001b[1m]\u001b[0m >> Initialize generator node - LlamaIndexLLM                   \u001b]8;id=230395;file:///home/lyb/RAG/AutoRAG/autorag/nodes/generator/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=734017;file:///home/lyb/RAG/AutoRAG/autorag/nodes/generator/base.py#19\u001b\\\u001b[2m19\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>base.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span><span style=\"font-weight: bold\">]</span> &gt;&gt; Running retrieval node - VectorDB module<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                 <a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mbase.py:\u001b[1;36m31\u001b[0m\u001b[1m]\u001b[0m >> Running retrieval node - VectorDB module\u001b[33m...\u001b[0m                 \u001b]8;id=909566;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=587206;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2541e0288494b5f83fd7dbb5de3ef02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/22/24 03:39:37] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>base.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span><span style=\"font-weight: bold\">]</span> &gt;&gt; Running retrieval node - BM25 module<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                     <a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/22/24 03:39:37]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mbase.py:\u001b[1;36m31\u001b[0m\u001b[1m]\u001b[0m >> Running retrieval node - BM25 module\u001b[33m...\u001b[0m                     \u001b]8;id=965018;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=160827;file:///home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/base.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyb/RAG/AutoRAG/autorag/nodes/retrieval/hybrid_cc.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_score = (arr - min_value) / (max_value - min_value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>base.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span><span style=\"font-weight: bold\">]</span> &gt;&gt; Running prompt maker node - Fstring module<span style=\"color: #808000; text-decoration-color: #808000\">...</span>               <a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/promptmaker/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/promptmaker/base.py#23\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">23</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mbase.py:\u001b[1;36m23\u001b[0m\u001b[1m]\u001b[0m >> Running prompt maker node - Fstring module\u001b[33m...\u001b[0m               \u001b]8;id=705491;file:///home/lyb/RAG/AutoRAG/autorag/nodes/promptmaker/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=229316;file:///home/lyb/RAG/AutoRAG/autorag/nodes/promptmaker/base.py#23\u001b\\\u001b[2m23\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>base.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span><span style=\"font-weight: bold\">]</span> &gt;&gt; Running generator node - LlamaIndexLLM module<span style=\"color: #808000; text-decoration-color: #808000\">...</span>            <a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/generator/base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lyb/RAG/AutoRAG/autorag/nodes/generator/base.py#26\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">26</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mbase.py:\u001b[1;36m26\u001b[0m\u001b[1m]\u001b[0m >> Running generator node - LlamaIndexLLM module\u001b[33m...\u001b[0m            \u001b]8;id=115989;file:///home/lyb/RAG/AutoRAG/autorag/nodes/generator/base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=705149;file:///home/lyb/RAG/AutoRAG/autorag/nodes/generator/base.py#26\u001b\\\u001b[2m26\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/22/24 03:39:43] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>_client.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1773</span><span style=\"font-weight: bold\">]</span> &gt;&gt; HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span>                                <a href=\"file:///home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/httpx/_client.py#1773\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1773</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">http://localhost:11434/api/chat</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/22/24 03:39:43]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0m_client.py:\u001b[1;36m1773\u001b[0m\u001b[1m]\u001b[0m >> HTTP Request: \u001b[1;33mPOST\u001b[0m                                \u001b]8;id=614998;file:///home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=50014;file:///home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/httpx/_client.py#1773\u001b\\\u001b[2m1773\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;94mhttp://localhost:11434/api/chat\u001b[0m \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                      \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Based on the passages provided, it seems that there is no clear answer to the question \"Who are you?\" as the passages appear to be unrelated and do not provide any information about the person\\'s identity or characteristics.\\n\\nHowever, if I had to make an educated guess based on the tone and style of the passages, I would say that the author appears to be someone who values honesty, openness, and creativity. The author seems to be comfortable sharing their thoughts and feelings with others, and is not afraid to express themselves freely.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autorag.deploy import Runner\n",
    "runner = Runner.from_yaml('./eli5/0/best.yaml', project_dir='./eli5')\n",
    "runner.run('who are you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node_lines': [{'node_line_name': 'retrieve_node_line',\n",
       "   'nodes': [{'modules': [{'module_type': 'HybridCC',\n",
       "       'target_module_params': [{'top_k': 3, 'vectordb': 'chroma_mpnet'},\n",
       "        {'top_k': 3}],\n",
       "       'target_modules': ['VectorDB', 'BM25'],\n",
       "       'top_k': 3,\n",
       "       'weight': 0.0,\n",
       "       'weights': [0.3, 0.7]}],\n",
       "     'node_type': 'retrieval',\n",
       "     'strategy': {'metrics': ['retrieval_f1',\n",
       "       'retrieval_recall',\n",
       "       'retrieval_precision']}}]},\n",
       "  {'node_line_name': 'post_retrieve_node_line',\n",
       "   'nodes': [{'modules': [{'module_type': 'Fstring',\n",
       "       'prompt': 'Read the passages and answer the given question. \\n Question: {query} \\n Passage: {retrieved_contents} \\n Answer : '}],\n",
       "     'node_type': 'prompt_maker',\n",
       "     'strategy': {'metrics': ['meteor', 'rouge', 'bert_score']}},\n",
       "    {'modules': [{'batch': 1,\n",
       "       'llm': 'ollama',\n",
       "       'model': 'llama3',\n",
       "       'module_type': 'LlamaIndexLLM',\n",
       "       'temperature': 0.5}],\n",
       "     'node_type': 'generator',\n",
       "     'strategy': {'metrics': ['meteor', 'rouge', 'bert_score']}}]}],\n",
       " 'vectordb': [{'client_type': 'persistent',\n",
       "   'collection_name': 'huggingface_all_mpnet_base_v2',\n",
       "   'db_type': 'chroma',\n",
       "   'embedding_model': 'huggingface_all_mpnet_base_v2',\n",
       "   'name': 'chroma_mpnet',\n",
       "   'path': '/home/lyb/RAG/experiments/chroma_mpnet'}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2;36m[12/21/24 16:19:56]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mconfig.py:\u001b[1;36m58\u001b[0m\u001b[1m]\u001b[0m >> PyTorch version      \u001b]8;id=239230;file:///home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/datasets/config.py\u001b\\\u001b[2mconfig.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=803982;file:///home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/datasets/config.py#58\u001b\\\u001b[2m58\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[1;36m2.5\u001b[0m.\u001b[1;36m1\u001b[0m available.                       \u001b[2m            \u001b[0m\n",
      "/home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_id\" in DeployedModel has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceLLM has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_kwargs\" in HuggingFaceLLM has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceInferenceAPI has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in TextGenerationInference has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "\u001b[2;36m[12/21/24 16:19:59]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0m_client.py:\u001b[1;36m1026\u001b[0m\u001b[1m]\u001b[0m >> HTTP Request:  \u001b]8;id=684912;file:///home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=418493;file:///home/lyb/.conda/envs/autorag/lib/python3.10/site-packages/httpx/_client.py#1026\u001b\\\u001b[2m1026\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[1;33mGET\u001b[0m                                 \u001b[2m               \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[4;94mhttps://api.gradio.app/gradio-messa\u001b[0m \u001b[2m               \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[4;94mging/en\u001b[0m \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m           \u001b[2m               \u001b[0m\n",
      "\n",
      "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
      "\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://144.214.37.75:8501\u001b[0m\n",
      "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://144.214.37.75:8501\u001b[0m\n",
      "\u001b[0m\n",
      "^C\n",
      "\u001b[34m  Stopping...\u001b[0m\n",
      "\n",
      "Aborted!\n"
     ]
    }
   ],
   "source": [
    "!autorag run_web --yaml_path ./eli5/0/best.yaml --project_dir ./eli5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autorag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
