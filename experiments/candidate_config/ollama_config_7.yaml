vectordb:
- name: default_vectordb
  collection_name: huggingface_all_mpnet_base_v2
  db_type: chroma
  embedding_batch: 100
  embedding_model: huggingface_all_mpnet_base_v2
  similarity_metric: cosine
  client_type: persistent
  host: localhost
  port: 8000
  ssl: false
  headers: null
  api_key: null
  tenant: default_tenant
  database: default_database
  path: /home/lyb/RAG/experiments/default_vectordb
node_lines:
- node_line_name: retrieve_node_line
  nodes:
  - strategy:
      metrics:
      - retrieval_f1
      - retrieval_recall
      - retrieval_precision
    node_type: retrieval
    modules:
    - module_type: hybrid_rrf
      top_k: 5
      weight: 21
      target_modules: ('bm25', 'vectordb')
      target_module_params:
      - top_k: 5
      - top_k: 5
        vectordb: default_vectordb
- - node_line_name: post_retrieve_node_line
    nodes:
    - node_type: prompt_maker
      strategy:
        metrics:
        - meteor
        - rouge
        - bert_score
      modules:
      - module_type: window_replacement
        prompt: "Question: {query} \n Something to read: {retrieved_contents} \n What's\
          \ your answer?"
    - node_type: generator
      strategy:
        metrics:
        - meteor
        - rouge
        - bert_score
      modules:
      - batch: 4
        max_token: 512
        module_type: LlamaIndexLLM
        temperature: 1.0
        llm: ollama
        model: llama3
        torch_dtype: float16
        api_base: your_api_base
        api_key: your_api_key
        request_timeout: 120.0
bm25_tokenizer_list:
- porter_stemmer
- space
strategies:
  metrics:
  - meteor
  - rouge
  - bert_score
