vectordb:
  - name: chroma_mpnet
    db_type: chroma
    client_type: persistent
    collection_name: huggingface_all_mpnet_base_v2
    embedding_model: huggingface_all_mpnet_base_v2
    path: /home/lyb/RAG/experiments/chroma_mpnet
node_lines:
  - node_line_name: retrieve_node_line
    nodes:
      - node_type: retrieval
        strategy:
          metrics: [ retrieval_f1, retrieval_recall, retrieval_precision ]
        top_k: 3
        modules:
          # - module_type: bm25
          # - module_type: vectordb
          #   vectordb: chroma_mpnet
          - module_type: hybrid_rrf
            target_modules: ('bm25', 'vectordb')
            rrf_k: [ 3, 5, 10 ]
          - module_type: hybrid_cc
            target_modules: ('bm25', 'vectordb')
            vectordb: chroma_mpnet
            weights: (0.5, 0.5)
  - node_line_name: post_retrieve_node_line
    nodes:
      - node_type: prompt_maker
        strategy:
          metrics: [ meteor, rouge, bert_score ]
        modules:
          - module_type: fstring
            prompt: "Read the passages and answer the given question. \n Question: {query} \n Passage: {retrieved_contents} \n Answer : "
      - node_type: generator
        strategy:
          metrics: [ meteor, rouge, bert_score ]
        modules:
          - module_type: llama_index_llm
            llm: ollama
            model: llama3
            temperature: 0.5
            batch: 1
